The main goal by is to have a fully functioning integrated system of a computing platform with hardware accelerated machine learning using an FPGA device. 
The computing platform is highly-mobile and easily deployable with the use of a unmanned multirotor aerial system (drone). 

The drone is piloted manually within the line-of-sight (LOS) of the pilot, using a ground-to-air transmistor (TX) either using an off-the-shelf radio controller and receiver combination, or WiFi. 
The drone features a flight controller capable of self-stabilization using well-tuned PIDs.
With the payload attached, the drone's flight duration should be at least 50\% that of without the payload (typically 10--15 minutes).
The total takeoff mass of the integrated system should not exceed 25 kilograms --- as specified by Transport Canada, a pilot with \textit{Basic Operations}
certificate or \textit{Advanced Operations} certificate cannot operate a drone heavier than 25kg.

On-board the drone, the camera sensor should stream video data to the processing hardware (including the FPGA). 
The FPGA act as a hardware accelerator to speedup ML related or parallel tasks such as matrix multiplication and convolution.
The hardware should sustain a reasonable quality of video at 640x480 (VGA) resolution at a rate of at least 10 frames per second (fps).
Both the video and the process ouput data are to be transmitted to a ground station, also sustaining the same sample rate and resolution.

The ground station is capable of receving the data transmitted by the hardware on the drone. The ground station device should be able
to decode and display the video and ML data in real time to the operator.